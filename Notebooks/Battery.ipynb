{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian process regression for forecasting battery state of health"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automotive industry has undergone significant changes with innovations like electrification and Autonomous Driving (ADAS). Electrificaiton, in general talks about many aspects but electrifying powertrain is the main focus area. Electrification is supposed to reduce the carbon footprint of vehicles, or at least isolate them away from cities where the major population resides around the world. According to this report from [EV Volumes](https://www.ev-volumes.com/country/total-world-plug-in-vehicle-volumes/) database, the YoY growth of EV sales showed average monotinic increasing trends despite the COVID situation economically.\n",
    "\n",
    "<img src=\"https://www.ev-volumes.com/wp-content/uploads/2021/01/WW-A-12-2020.png\" width=\"800\" />\n",
    "\n",
    "\n",
    "The Li-ion battery (LiB) technology is the backbone of electrified powertrain. A strong and reliable LiB technology entails early and robust adaptation of electrified powertrain. To that end, LiB development has many challenges. One among these is the prediction of Age of LiB cells as it is a multiscale and multiphysics problem at core. If the LiB cell capacity history is known, forecasting the State of Health (SoH) is a challenge, because this is governed by many external and user specific aspects. \n",
    "\n",
    "In this [paper](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwjqmJ_855bvAhUVgOYKHR4lByAQFjAAegQIBBAD&url=https%3A%2F%2Fwww.sciencedirect.com%2Fscience%2Farticle%2Fpii%2FS0378775317306250&usg=AOvVaw1P31v8I4zlOJacXNwqw_xP), the authors have tried to make use of Gaussian Process Regression (GPR) for this forecasting task. This notebook attempts to recreate the results from the paper. \n",
    "\n",
    "This \n",
    "\n",
    "#Table of content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table of content\n",
    "\n",
    "> 1. Basic Single Output GP Results\n",
    ">> 1.1. Kernel Function Selection\n",
    ">>\n",
    ">>1.2. Kernel Function Decomposition\n",
    ">>\n",
    ">>1.3. Short-term Lookahead Prediction\n",
    ">>\n",
    ">>1.4 Remaining Useful Life Prediction\n",
    "> 2. Encoding exponential degradation via EMFs Results\n",
    "> 3. Capturing Cell-to-Cell Correlations via Multi-output GPs Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some imports relevant to this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseKernel:\n",
    "    def __init__(self, length_scale=1.0, length_scale_bounds=(1e-1, 1e3)):\n",
    "        self.length_scale=length_scale\n",
    "        self.length_scale_bounds=length_scale_bounds\n",
    "\n",
    "\n",
    "class Linear(BaseKernel):\n",
    "    def __call__(self, x1, x2):\n",
    "        return self.length_scale * np.dot(x1, x2.T)\n",
    "\n",
    "\n",
    "class Matern1_5(BaseKernel):\n",
    "    def __call__(self, x1, x2):\n",
    "        return (1+np.sqrt(3)/self.length_scale)*np.exp(-np.sqrt(3)/self.length_scale*np.linalg.norm(x1-x2))\n",
    "    \n",
    "    \n",
    "class Matern2_5(BaseKernel):\n",
    "    def __call__(self, x1, x2):\n",
    "        return (1+np.sqrt(5)/self.length_scale*np.linalg.norm(x1-x2)+\n",
    "                5/(3*self.length_scale)*np.linalg.norm(x1-x2)*np.linalg.norm(x1-x2))*np.exp(-np.sqrt(5)/self.length_scale*np.linalg.norm(x1-x2))\n",
    "\n",
    "    \n",
    "class Periodic(BaseKernel):\n",
    "    def __init__(self, periodicity=0.5, periodicity_bounds=(1e-1,1e5)):\n",
    "        super().__init__()\n",
    "        self.periodicity=periodicity\n",
    "        self.periodicity_bounds=periodicity_bounds\n",
    "    def __call__(self, x1, x2):\n",
    "        return np.exp(-2*np.sin(np.pi*np.linalg.norm(x1-x2)/self.periodicity)*np.sin(np.pi*np.linalg.norm(x1-x2)/self.periodicity)/(self.length_scale**2))\n",
    "    \n",
    "\n",
    "class SquaredExponential(BaseKernel):\n",
    "    def __call__(self, x1, x2):\n",
    "        return np.exp(-(np.linalg.norm(x1 - x2)**2)/(2*self.length_scale**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 10.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = Periodic()\n",
    "k.periodicity, k.length_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dimension.\n",
    "d = 1\n",
    "# Number of samples (training set). \n",
    "n = 500\n",
    "\n",
    "x = np.linspace(start=0, stop=1, num=n)\n",
    "\n",
    "def f(x):\n",
    "    f = np.sin((4*np.pi)*x) + np.sin((7*np.pi)*x)\n",
    "    return(f)\n",
    "\n",
    "f_x = f(x)\n",
    "\n",
    "sigma_n = 0.4\n",
    "# Errors.\n",
    "epsilon = np.random.normal(loc=0, scale=sigma_n, size=n)\n",
    "# Observed target variable. \n",
    "y = f_x + epsilon\n",
    "\n",
    "n_star = 100\n",
    "\n",
    "x_star = np.linspace(start=0, stop=1, num=n_star)\n",
    "\n",
    "\n",
    "import itertools\n",
    "covar = [k(i, j) for (i, j) in itertools.product(x, x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(np.array(covar).reshape(n,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sin(90*np.pi/180),np.cos(90*np.pi/180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.matern_3_by_2(x,x), k.matern_5_by_2(x,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Single Output GP Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Function Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Function Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short-term Lookahead Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remaining Useful Life Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding exponential degradation via EMFs Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capturing Cell-to-Cell Correlations via Multi-output GPs Results"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "batt_dict = {}\n",
    "for i in range(9,10):\n",
    "    batt_dict[str(i)] = battery(i)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "for i in range(1,29):\n",
    "    plt.plot(batt_dict[str(i)].time, batt_dict[str(i)].capacity, 'o--')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_orig = batt_dict[\"9\"].time.reshape(-1,1)\n",
    "y_orig = batt_dict[\"9\"].capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_battery_data(name):\n",
    "    data = pd.read_csv(\"./data/\"+name+\".csv\", header=None)\n",
    "    X_ = data[0].values.reshape(-1,1)\n",
    "    y_ = data[1].values\n",
    "    return X_, y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_names = [\"A1\", \"A2\", \"A3\", \"A4\", \"B1\", \"B2\", \"B3\", \"B4\"]\n",
    "styles = [\"--k\",\"-k\",\"-ok\",\"-dk\",\"-b\",\"--b\",\"-ob\",\"-db\"]\n",
    "plt.figure(figsize=(20,10))\n",
    "for i in range(len(cell_names)):\n",
    "    X, y = get_battery_data(cell_names[i])\n",
    "    plt.plot(X, y, styles[i], label=cell_names[i])\n",
    "plt.legend()\n",
    "plt.ylim(0.7,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 = pd.read_csv(\"./data/B3.csv\", header=None)\n",
    "X_orig = A1[0].values.reshape(-1,1)\n",
    "y_orig = A1[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_till = 100\n",
    "X = X_orig[np.where(X_orig<learn_till)].reshape(-1,1)\n",
    "y = y_orig[np.where(X_orig<learn_till)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process.kernels import ExpSineSquared, Matern, WhiteKernel, ExpSineSquared\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "ma5 = Matern(length_scale=8e3,nu=5/2, length_scale_bounds=(1e-1, 5e3))\n",
    "ma3 = Matern(length_scale=1e2,nu=3/2, length_scale_bounds=(1e-1, 5e2))\n",
    "pe = ExpSineSquared(length_scale=1.0, periodicity=1.0, length_scale_bounds=(1e-05, 1e6), periodicity_bounds=(1e-05, 1e6))\n",
    "\n",
    "kernel = ma5+ma3\n",
    "gp = GaussianProcessRegressor(kernel=kernel,normalize_y=False, alpha=0.001, n_restarts_optimizer=20)\n",
    "\n",
    "gp.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.log_marginal_likelihood_value_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.kernel_.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.atleast_2d(np.linspace(0,167,100)).T\n",
    "y_pred, sigma = gp.predict(x, return_std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(x, y_pred)\n",
    "plt.fill(np.concatenate([x, x[::-1]]),np.concatenate([y_pred -  sigma,(y_pred + sigma)[::-1]]), alpha=0.1)\n",
    "plt.plot(X_orig, y_orig, c='k')\n",
    "plt.plot()\n",
    "plt.ylim(0.5,1.05)\n",
    "plt.axhline(y=0.775, c='k')\n",
    "plt.axvline(x=learn_till, c='r', linestyle='--')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
